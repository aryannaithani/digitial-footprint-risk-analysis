{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "ALLOWED_TASKS = [\n",
    "    \"check_breach_exposure\",\n",
    "    \"analyze_github_public_data\",\n",
    "    \"check_username_reuse\",\n",
    "    \"analyze_bio_exposure\"\n",
    "]\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def planner_agent_llm(user_input: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    LLM-based Planner Agent using Gemini\n",
    "\n",
    "    - Decides which analysis tasks are relevant\n",
    "    - Enforces a strict JSON output schema\n",
    "    - Sanitizes output to prevent hallucinated tasks\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a planner agent for a cyber risk analysis system.\n",
    "\n",
    "Your ONLY job:\n",
    "- Look at the user input\n",
    "- Decide which analysis tasks apply\n",
    "\n",
    "STRICT RULES:\n",
    "- You may ONLY select tasks from the allowed list below\n",
    "- Do NOT invent new tasks\n",
    "- Do NOT explain your reasoning\n",
    "- Do NOT use markdown or code blocks\n",
    "- Output MUST be valid JSON and nothing else\n",
    "\n",
    "Allowed tasks:\n",
    "{ALLOWED_TASKS}\n",
    "\n",
    "User input:\n",
    "{json.dumps(user_input, indent=2)}\n",
    "\n",
    "Return JSON in EXACTLY this format:\n",
    "{{\n",
    "  \"tasks\": [string],\n",
    "  \"notes\": [string]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    # Gemini sometimes adds code fences; remove them safely\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = raw.strip(\"```\").strip()\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"normalized_input\": user_input,\n",
    "            \"tasks\": [],\n",
    "            \"notes\": [\"Planner LLM returned invalid JSON\"]\n",
    "        }\n",
    "\n",
    "    raw_tasks = parsed.get(\"tasks\", [])\n",
    "    notes = parsed.get(\"notes\", [])\n",
    "\n",
    "    # Enforce whitelist\n",
    "    tasks: List[str] = [t for t in raw_tasks if t in ALLOWED_TASKS]\n",
    "\n",
    "    if not tasks:\n",
    "        notes.append(\"No valid tasks selected by planner\")\n",
    "\n",
    "    return {\n",
    "        \"normalized_input\": user_input,\n",
    "        \"tasks\": tasks,\n",
    "        \"notes\": notes\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = {\n",
    "    \"email\": \"aryannaithani1085@gmail.com\",\n",
    "    \"github\": \"https://github.com/aryannaithani\",\n",
    "    \"username\": \"aryannaithani\",\n",
    "    \"bio\": \"CS student interested in security\"\n",
    "}\n",
    "\n",
    "#planner_output = planner_agent_llm(test_input)\n",
    "#planner_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0af951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_github_public_data(username: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch basic public GitHub profile data.\n",
    "\n",
    "    Public, unauthenticated, best-effort.\n",
    "    Falls back gracefully on failure.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://api.github.com/users/{username}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return {\n",
    "                \"public_repos\": None,\n",
    "                \"commit_email_exposed\": None,\n",
    "                \"error\": f\"GitHub API returned {response.status_code}\"\n",
    "            }\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        return {\n",
    "            \"public_repos\": data.get(\"public_repos\"),\n",
    "            # heuristic placeholder; real check would require repo scan\n",
    "            \"commit_email_exposed\": True\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"public_repos\": None,\n",
    "            \"commit_email_exposed\": None,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "#import requests\n",
    "\n",
    "def check_email_breach_leakcheck(email: str) -> dict:\n",
    "    \"\"\"\n",
    "    Check email exposure using LeakCheck public API.\n",
    "\n",
    "    Uses publicly available breach data.\n",
    "    No API key required.\n",
    "    Fails gracefully.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://leakcheck.net/api/public?check={email}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            return {\n",
    "                \"found_in_breaches\": None,\n",
    "                \"breach_sources\": [],\n",
    "                \"error\": f\"LeakCheck returned {response.status_code}\"\n",
    "            }\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        # LeakCheck response format can vary slightly, so be defensive\n",
    "        found = bool(data.get(\"found\", False))\n",
    "        sources = []\n",
    "\n",
    "        if found:\n",
    "            # Try to extract source names if present\n",
    "            sources = data.get(\"sources\", [])\n",
    "            if not isinstance(sources, list):\n",
    "                sources = []\n",
    "\n",
    "        return {\n",
    "            \"found_in_breaches\": found,\n",
    "            \"breach_sources\": sources\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"found_in_breaches\": None,\n",
    "            \"breach_sources\": [],\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "#import requests\n",
    "PLATFORMS = {\n",
    "    \"GitHub\": \"https://github.com/{username}\",\n",
    "    \"Reddit\": \"https://www.reddit.com/user/{username}\",\n",
    "    \"Dev.to\": \"https://dev.to/{username}\",\n",
    "    \"Medium\": \"https://medium.com/@{username}\",\n",
    "    \"Twitter\": \"https://twitter.com/{username}\"\n",
    "}\n",
    "\n",
    "\n",
    "def check_username_reuse(username: str) -> dict:\n",
    "    \"\"\"\n",
    "    Check username reuse across major platforms using existence checks.\n",
    "\n",
    "    - No auth\n",
    "    - No scraping\n",
    "    - Best-effort, fail-safe\n",
    "    \"\"\"\n",
    "\n",
    "    found_platforms = []\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"DigitalFootprintRiskAgent\"\n",
    "    }\n",
    "\n",
    "    for platform, url_template in PLATFORMS.items():\n",
    "        url = url_template.format(username=username)\n",
    "\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, timeout=8, allow_redirects=True)\n",
    "\n",
    "            # Heuristic:\n",
    "            # 200 -> exists\n",
    "            # 404 -> does not exist\n",
    "            # 429/403 -> skip quietly\n",
    "            if resp.status_code == 200:\n",
    "                found_platforms.append(platform)\n",
    "\n",
    "        except Exception:\n",
    "            # Ignore platform failures completely\n",
    "            continue\n",
    "\n",
    "    return {\n",
    "        \"value\": username,\n",
    "        \"reuse_count\": len(found_platforms),\n",
    "        \"platforms\": found_platforms\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gathering_agent(planner_output: dict) -> dict:\n",
    "    tasks = planner_output.get(\"tasks\", [])\n",
    "    inputs = planner_output.get(\"normalized_input\", {})\n",
    "\n",
    "    evidence = {}\n",
    "\n",
    "    # ---- Email breach intelligence (LeakCheck – REAL DATA) ----\n",
    "    if \"check_breach_exposure\" in tasks and \"email\" in inputs:\n",
    "        breach_data = check_email_breach_leakcheck(inputs[\"email\"])\n",
    "\n",
    "        evidence[\"email\"] = {\n",
    "            \"value\": inputs[\"email\"],\n",
    "            \"found_in_breaches\": breach_data.get(\"found_in_breaches\"),\n",
    "            \"breach_sources\": breach_data.get(\"breach_sources\", [])\n",
    "        }\n",
    "\n",
    "    # ---- GitHub public data (already integrated) ----\n",
    "    if \"analyze_github_public_data\" in tasks and \"username\" in inputs:\n",
    "        username = inputs[\"username\"].rstrip(\"/\").split(\"/\")[-1]\n",
    "        github_data = fetch_github_public_data(username)\n",
    "\n",
    "        evidence[\"github\"] = {\n",
    "            \"username\": username,\n",
    "            \"public_repos\": github_data.get(\"public_repos\"),\n",
    "            \"commit_email_exposed\": github_data.get(\"commit_email_exposed\")\n",
    "        }\n",
    "\n",
    "        # ---- Username reuse detection (REAL TOOL) ----\n",
    "    if \"check_username_reuse\" in tasks and \"username\" in inputs:\n",
    "        username_data = check_username_reuse(inputs[\"username\"])\n",
    "\n",
    "        evidence[\"username\"] = {\n",
    "            \"value\": username_data[\"value\"],\n",
    "            \"reuse_count\": username_data[\"reuse_count\"],\n",
    "            \"platforms\": username_data[\"platforms\"]\n",
    "        }\n",
    "\n",
    "\n",
    "    return evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evidence = information_gathering_agent(planner_output)\n",
    "evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def output_generator_agent(evidence: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Output Generator Agent\n",
    "\n",
    "    - Uses an LLM to analyze collected evidence\n",
    "    - Produces a structured cyber risk assessment\n",
    "    - Outputs JSON only (no prose)\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a cyber risk analysis agent.\n",
    "\n",
    "Your job:\n",
    "- Analyze the provided evidence\n",
    "- Compute a cyber risk score between 0 and 100\n",
    "- Assign a risk level (Low, Medium, High)\n",
    "- List the main risk factors\n",
    "- Suggest concrete mitigation steps\n",
    "\n",
    "STRICT RULES:\n",
    "- Use ONLY the evidence provided\n",
    "- Do NOT invent facts\n",
    "- Do NOT mention tools or APIs\n",
    "- Do NOT output explanations outside JSON\n",
    "- Output MUST be valid JSON\n",
    "- Do NOT use markdown or code blocks\n",
    "\n",
    "Risk level thresholds:\n",
    "- 0–30: Low\n",
    "- 31–60: Medium\n",
    "- 61–100: High\n",
    "\n",
    "Evidence:\n",
    "{json.dumps(evidence, indent=2)}\n",
    "\n",
    "Return JSON in EXACTLY this format:\n",
    "{{\n",
    "  \"risk_score\": number,\n",
    "  \"risk_level\": \"Low|Medium|High\",\n",
    "  \"risk_factors\": [string],\n",
    "  \"mitigations\": [string]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    # Gemini sometimes adds code fences\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = raw.strip(\"```\").strip()\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"risk_score\": 0,\n",
    "            \"risk_level\": \"Low\",\n",
    "            \"risk_factors\": [],\n",
    "            \"mitigations\": [\"Unable to generate risk assessment due to parsing error\"]\n",
    "        }\n",
    "\n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ebd110",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_output = output_generator_agent(evidence)\n",
    "draft_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53968ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def evaluator_agent(\n",
    "    evidence: Dict[str, Any],\n",
    "    draft_output: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluator Agent\n",
    "\n",
    "    - Verifies that all risk factors are supported by evidence\n",
    "    - Removes unsupported or speculative claims\n",
    "    - Produces a clean, user-facing final report\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an evaluator agent for a cyber risk analysis system.\n",
    "\n",
    "Your job:\n",
    "- Review the draft risk assessment\n",
    "- Cross-check it against the provided evidence\n",
    "- Remove or correct any unsupported claims\n",
    "- Produce a final, concise report for the user\n",
    "\n",
    "STRICT RULES:\n",
    "- Use ONLY the provided evidence\n",
    "- Do NOT invent new risk factors\n",
    "- Do NOT change the risk score arbitrarily\n",
    "- If a risk factor is unsupported, remove it\n",
    "- Output MUST be valid JSON\n",
    "- Do NOT use markdown or code blocks\n",
    "\n",
    "Evidence:\n",
    "{json.dumps(evidence, indent=2)}\n",
    "\n",
    "Draft risk assessment:\n",
    "{json.dumps(draft_output, indent=2)}\n",
    "\n",
    "Return JSON in EXACTLY this format:\n",
    "{{\n",
    "  \"summary\": string,\n",
    "  \"risk_score\": number,\n",
    "  \"risk_level\": string,\n",
    "  \"validated_risk_factors\": [string],\n",
    "  \"validated_mitigations\": [string]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    # Gemini code-fence cleanup\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = raw.strip(\"```\").strip()\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"summary\": \"Unable to generate final report due to evaluation error\",\n",
    "            \"risk_score\": draft_output.get(\"risk_score\", 0),\n",
    "            \"risk_level\": draft_output.get(\"risk_level\", \"Low\"),\n",
    "            \"validated_risk_factors\": [],\n",
    "            \"validated_mitigations\": []\n",
    "        }\n",
    "\n",
    "    return parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37684de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = evaluator_agent(evidence, draft_output)\n",
    "final_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(user_input: dict) -> dict:\n",
    "    planner_output = planner_agent_llm(user_input)\n",
    "    evidence = information_gathering_agent(planner_output)\n",
    "    draft_output = output_generator_agent(evidence)\n",
    "    final_report = evaluator_agent(evidence, draft_output)\n",
    "    return final_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c2f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {\n",
    "    \"email\": \"User@Example.com\",\n",
    "    \"github\": \"https://github.com/octocat\",\n",
    "    \"username\": \"octocat\",\n",
    "    \"bio\": \"CS student interested in security\"\n",
    "}\n",
    "\n",
    "final_report = run_full_pipeline(user_input)\n",
    "final_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e946b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Dict, Any\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_input: Dict[str, Any]\n",
    "    planner_output: Dict[str, Any]\n",
    "    evidence: Dict[str, Any]\n",
    "    draft_output: Dict[str, Any]\n",
    "    final_report: Dict[str, Any]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ced14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    state[\"planner_output\"] = planner_agent_llm(state[\"user_input\"])\n",
    "    return state\n",
    "\n",
    "def gather_node(state: AgentState) -> AgentState:\n",
    "    state[\"evidence\"] = information_gathering_agent(state[\"planner_output\"])\n",
    "    return state\n",
    "\n",
    "def generate_node(state: AgentState) -> AgentState:\n",
    "    state[\"draft_output\"] = output_generator_agent(state[\"evidence\"])\n",
    "    return state\n",
    "\n",
    "def evaluate_node(state: AgentState) -> AgentState:\n",
    "    state[\"final_report\"] = evaluator_agent(\n",
    "        state[\"evidence\"], state[\"draft_output\"]\n",
    "    )\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8735ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"planner\", planner_node)\n",
    "graph.add_node(\"gather\", gather_node)\n",
    "graph.add_node(\"generate\", generate_node)\n",
    "graph.add_node(\"evaluate\", evaluate_node)\n",
    "\n",
    "graph.set_entry_point(\"planner\")\n",
    "\n",
    "graph.add_edge(\"planner\", \"gather\")\n",
    "graph.add_edge(\"gather\", \"generate\")\n",
    "graph.add_edge(\"generate\", \"evaluate\")\n",
    "graph.add_edge(\"evaluate\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"user_input\": {\n",
    "        \"email\": \"User@Example.com\",\n",
    "        \"github\": \"https://github.com/octocat\",\n",
    "        \"username\": \"octocat\",\n",
    "        \"bio\": \"CS student interested in security\"\n",
    "    },\n",
    "    \"planner_output\": {},\n",
    "    \"evidence\": {},\n",
    "    \"draft_output\": {},\n",
    "    \"final_report\": {}\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "print(result[\"planner_output\"])\n",
    "print(result[\"evidence\"])\n",
    "print(result[\"draft_output\"])\n",
    "print(result[\"final_report\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
